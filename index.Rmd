---
title: "Predicting the Quality of a Workout"
author: "Ben Kling"
date: "4/15/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(parallel)
library(doParallel)
library(randomForest)
```

## Predicting Quality of a workout

In this project, we will attempt to use statistical learning to make predictions
about the manner in which a user performed an exercise. We are given data from 
accelerometers that take measurements from the belt, forearm, arm, and dumbbell.

The goal is to accurately predict a value called "classe" given a sample of
19,622 labelled observations.


## Analysis

### Model Selection
Given that this is a classification problem, I have chosen to use a random 
forest model with which to build a prediction. There are many possible models
to choose from, but with how robust of a sample that we are given it is likely



### Model Parameters

Performance Notes

Accuracy - in sample, out of sample

Predictions against the evaluation (unlabelled) set



```{r file download and data frame initialization, echo=FALSE}
# Download the training file
if(!file.exists("pml-training.csv")) download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")
# Download the test file
if(!file.exists("pml-testing.csv")) download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv")

# establish data frame
rawdata <- read_csv("pml-training.csv")
evaluationraw <- read_csv("pml-testing.csv")

```

```{r data cleaning}

# #DIV/0! values
data <- rawdata %>%
    mutate(across(.fns=na_if, y="#DIV/0!")) %>% # lots of "#DIV/0" errors in the data (excel output?)
    mutate(across(.cols = -c(1:7,160), .fns = as.numeric)) %>% # Coerce to numeric
    mutate(across(.cols = -c(1:7,160), .fns = replace_na, replace=0)) %>% # zero out the NA values
    filter(!is.na(classe)) %>% # remove NA classe values
    mutate(classe = as.factor(classe)) # convert classe to a factor


evaluationdata <- evaluationraw %>%
    mutate(across(.fns=na_if, y="#DIV/0!")) %>% # lots of "#DIV/0" errors in the data (excel output?)
    mutate(across(.cols = -c(1:7,160), .fns = as.numeric)) %>% # Coerce to numeric
    mutate(across(.cols = -c(1:7,160), .fns = replace_na, replace=0)) # zero out the NA values




# these features have ONLY ZERO values
allzero <- c('kurtosis_yaw_belt',
             'skewness_yaw_belt', 
             'amplitude_yaw_belt', 
             'kurtosis_yaw_dumbbell', 
             'skewness_yaw_dumbbell', 
             'amplitude_yaw_dumbbell', 
             'kurtosis_yaw_forearm', 
             'skewness_yaw_forearm', 
             'amplitude_yaw_forearm')

data <- data %>%
    select(-allzero)

evaluationdata <- evaluationdata %>%
    select(-allzero)

# first 7 variables are not measurements, merely attributes and can be ignored
data_processed <- data %>% select(-(1:7)) 
evaluation_processed <- evaluationdata %>% select(-(1:7))


# hold out 20 % of training data for validation purposes, to estimate out of 
# sample error

# set seed for reproducibility
set.seed(1234)

trainIndex <- createDataPartition(data_processed$classe,
                                  p=0.8,
                                  list=FALSE,
                                  times=1
                                  )

train_data <- data_processed[trainIndex,]
test_data <- data_processed[-trainIndex,]

```

```{r eda plots}

g <- ggplot(train_data, mapping = aes(max_roll_belt, fill=classe, color=classe))
g + geom_histogram()
g + geom_histogram() + facet_wrap(~classe)
```

```{r eda and qa slicing}

for (var in allzero) {
    rawdata %>%
        group_by(.data[[var]]) %>% 
        summarize(ct = n()) %>%
        head(n=12) %>%
        print()
}

```

```{r model selection, cache=TRUE}

# apply pca
# run random forest on the reduced feature set
# parallellize the execution

set.seed(1234) #set a seed for reproducibility

cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

fitCtrl <- trainControl(method='cv',
                        number=5,
                        allowParallel=TRUE)

rfmodel <- train(classe ~.,
                 data=train_data,
                 method='rf',
                 trControl=fitCtrl)

stopCluster(cluster)
registerDoSEQ()
```


```{r model evaluation}

rfmodel 

rfmodel$resample

confusionMatrix.train(rfmodel)

```

```{r predicting test data}

pred <- predict(rfmodel, 
                test_data)

confusionMatrix(test_data$classe,pred)

```


```{r predict the evaluation data1}

eval_pred <- predict(rfmodel,
                     evaluation_processed)

# print predictions
i <- 1
for (j in eval_pred) {
    print(paste0(i," ", j))    
    i <- i + 1
}


```



### Citations and References

All data in this analysis was made available here: <https://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>
An excellent guide to parallelizing model training by Leonard Greski, here <https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md>
